# ğŸ¤– AI Legal Assistant - Trá»£ lÃ½ AI TÆ° váº¥n PhÃ¡p luáº­t

Má»™t á»©ng dá»¥ng web sá»­ dá»¥ng AI Ä‘á»ƒ tÆ° váº¥n cÃ¡c váº¥n Ä‘á» phÃ¡p luáº­t Viá»‡t Nam, Ä‘Æ°á»£c xÃ¢y dá»±ng vá»›i FastAPI vÃ  Qwen2 model.

## TÃ­nh nÄƒng

- **TÆ° váº¥n phÃ¡p luáº­t chuyÃªn nghiá»‡p**: Tráº£ lá»i cÃ¡c cÃ¢u há»i vá» phÃ¡p luáº­t Viá»‡t Nam
- **Giao diá»‡n web thÃ¢n thiá»‡n**: Chat interface dá»… sá»­ dá»¥ng
- **Streaming response**: Hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i theo thá»i gian thá»±c
- **Há»— trá»£ GPU**: Tá»‘i Æ°u hÃ³a cho NVIDIA GPU (RTX 4080)
- **Lá»‹ch sá»­ chat**: LÆ°u trá»¯ vÃ  hiá»ƒn thá»‹ lá»‹ch sá»­ trÃ² chuyá»‡n

## CÃ´ng nghá»‡ sá»­ dá»¥ng

- **Backend**: FastAPI, Python
- **AI Model**: Qwen2 (trained checkpoint)
- **Frontend**: HTML, CSS, JavaScript
- **Deep Learning**: PyTorch, Transformers
- **GPU Support**: CUDA 12.1, NVIDIA RTX 4080

## YÃªu cáº§u há»‡ thá»‘ng

- Python 3.11+
- NVIDIA GPU (khuyáº¿n nghá»‹ RTX 4080 hoáº·c tÆ°Æ¡ng Ä‘Æ°Æ¡ng)
- CUDA 12.1+
- RAM: 16GB+
- VRAM: 8GB+ (cho GPU)

## CÃ i Ä‘áº·t

### 1. Clone repository
```bash
git clone <your-repository-url>
cd your-path
```

### 2. CÃ i Ä‘áº·t dependencies
```bash
pip install -r requirements.txt
```

### 3. CÃ i Ä‘áº·t PyTorch vá»›i CUDA support
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### 4. CÃ i Ä‘áº·t thÆ° viá»‡n Qwen
```bash
pip install qwen
```

## Sá»­ dá»¥ng

### Khá»Ÿi Ä‘á»™ng á»©ng dá»¥ng
```bash
python app.py
```

### Truy cáº­p á»©ng dá»¥ng
Má»Ÿ trÃ¬nh duyá»‡t vÃ  truy cáº­p: `http://127.0.0.1:8000`

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
inference_simpleQA_dsp391m/
â”œâ”€â”€ app.py                 # FastAPI application
â”œâ”€â”€ inference.py           # AI model inference logic
â”œâ”€â”€ checkpoint/            # Trained Qwen2 model checkpoint
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ static/               # Frontend files
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ style.css
â”‚   â”œâ”€â”€ chat.js
â”‚   â””â”€â”€ ...
â”œâ”€â”€ img/                  # Images and icons
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ Dockerfile           # Docker configuration
â”œâ”€â”€ docker-compose.yml   # Docker Compose
â””â”€â”€ README.md           # This file
```

## Cáº¥u hÃ¬nh

### Model Configuration
- **Model Type**: Qwen2
- **Architecture**: Qwen2ForCausalLM
- **Hidden Size**: 896
- **Layers**: 24
- **Attention Heads**: 14
- **Vocab Size**: 151,936
- **Max Position**: 32,768

### Generation Parameters
- **Max New Tokens**: 512
- **Temperature**: 0.7
- **Top-p**: 0.9
- **Repetition Penalty**: 1.1
- **Beam Search**: 1

## Giao diá»‡n

á»¨ng dá»¥ng cÃ³ giao diá»‡n web hiá»‡n Ä‘áº¡i vá»›i:
- Chat interface thÃ¢n thiá»‡n
- Streaming responses
- Responsive design
- Dark/Light theme
- Custom background support

## Hiá»‡u suáº¥t

- **CPU Mode**: ~12-15 giÃ¢y/cÃ¢u tráº£ lá»i
- **GPU Mode**: ~4-5 giÃ¢y/cÃ¢u tráº£ lá»i (RTX 4080)
- **Memory Usage**: ~8GB VRAM
- **Model Size**: ~3GB (float16)

## CÃ¡c chá»§ Ä‘á» phÃ¡p luáº­t Ä‘Æ°á»£c há»— trá»£

- Quyá»n lao Ä‘á»™ng
- Há»£p Ä‘á»“ng
- ÄÄƒng kÃ½ kinh doanh
- Thuáº¿
- Sá»Ÿ há»¯u trÃ­ tuá»‡
- Giao thÃ´ng
- NghÄ©a vá»¥ quÃ¢n sá»±
- VÃ  nhiá»u chá»§ Ä‘á» khÃ¡c...

## ğŸ³ Docker

### Build vÃ  cháº¡y vá»›i Docker
```bash
docker-compose up --build
```

### Hoáº·c sá»­ dá»¥ng Dockerfile
```bash
docker build -t ai-legal-assistant .
docker run -p 8000:8000 ai-legal-assistant
```

## ğŸ”§ Troubleshooting

### Lá»—i CUDA khÃ´ng kháº£ dá»¥ng
```bash
# Kiá»ƒm tra CUDA
python -c "import torch; print(torch.cuda.is_available())"

# CÃ i Ä‘áº·t láº¡i PyTorch vá»›i CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### Lá»—i model loading
```bash
# Kiá»ƒm tra checkpoint
ls -la checkpoint/

# Test model loading
python test_model.py
```

### Lá»—i memory
- Giáº£m `max_new_tokens` trong `inference.py`
- Sá»­ dá»¥ng `torch.float16` thay vÃ¬ `torch.float32`
- TÄƒng swap memory

## API Endpoints

### POST /chat
Gá»­i cÃ¢u há»i vÃ  nháº­n cÃ¢u tráº£ lá»i

**Request:**
```json
{
  "question": "CÃ¢u há»i phÃ¡p luáº­t",
  "chat_history": []
}
```

**Response:**
```
Streaming text response
```
â­ Náº¿u dá»± Ã¡n nÃ y há»¯u Ã­ch, hÃ£y cho má»™t star! 
