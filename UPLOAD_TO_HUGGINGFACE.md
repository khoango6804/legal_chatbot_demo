# ğŸ“¤ HÆ°á»›ng Dáº«n Upload Model LÃªn Hugging Face Hub

## ğŸ¯ Táº¡i Sao NÃªn DÃ¹ng Hugging Face Hub?

âœ… **Lá»£i Ã­ch:**
- KhÃ´ng cáº§n Git LFS
- KhÃ´ng cáº§n external storage
- Tá»± Ä‘á»™ng cache trÃªn server
- Dá»… dÃ ng version control
- Miá»…n phÃ­ cho public repos
- Tá»± Ä‘á»™ng download khi cáº§n

## ğŸ“‹ YÃªu Cáº§u

1. TÃ i khoáº£n Hugging Face: https://huggingface.co/join
2. CÃ i Ä‘áº·t `huggingface-hub`:
   ```bash
   pip install huggingface-hub
   ```
3. Login vÃ o Hugging Face:
   ```bash
   huggingface-cli login
   ```

## ğŸš€ CÃ¡c BÆ°á»›c Upload

### BÆ°á»›c 1: Chuáº©n Bá»‹ Model

Äáº£m báº£o model checkpoint Ä‘Ã£ cÃ³ Ä‘áº§y Ä‘á»§ files:
```
qwen3-0.6B-instruct-trafficlaws/
â””â”€â”€ model/
    â”œâ”€â”€ config.json
    â”œâ”€â”€ tokenizer.json
    â”œâ”€â”€ tokenizer_config.json
    â”œâ”€â”€ vocab.json
    â”œâ”€â”€ merges.txt
    â”œâ”€â”€ special_tokens_map.json
    â”œâ”€â”€ added_tokens.json
    â”œâ”€â”€ chat_template.jinja
    â””â”€â”€ model.safetensors (hoáº·c model.bin, model-*.safetensors)
```

### BÆ°á»›c 2: Táº¡o Repository TrÃªn Hugging Face

1. VÃ o https://huggingface.co/new
2. Chá»n **Model**
3. Äáº·t tÃªn: `qwen3-0.6B-instruct-trafficlaws` (hoáº·c tÃªn báº¡n muá»‘n)
4. Chá»n **Public** hoáº·c **Private**
5. Click **Create repository**

### BÆ°á»›c 3: Upload Model

**CÃ¡ch 1: DÃ¹ng Python Script**

Táº¡o file `upload_model.py`:

```python
from huggingface_hub import HfApi, login
import os

# Login (hoáº·c dÃ¹ng token)
# login(token="your_token_here")
# Hoáº·c Ä‘Ã£ login qua CLI: huggingface-cli login

api = HfApi()

# Repository name (thay báº±ng username/repo cá»§a báº¡n)
repo_id = "your-username/qwen3-0.6B-instruct-trafficlaws"

# ÄÆ°á»ng dáº«n Ä‘áº¿n model folder
model_path = "./qwen3-0.6B-instruct-trafficlaws/model"

print(f"Uploading model to {repo_id}...")
print(f"From: {model_path}")

# Upload toÃ n bá»™ folder
api.upload_folder(
    folder_path=model_path,
    repo_id=repo_id,
    repo_type="model",
    ignore_patterns=["*.git*", "*.DS_Store"]
)

print(f"âœ… Upload completed! Model available at: https://huggingface.co/{repo_id}")
```

Cháº¡y script:
```bash
python upload_model.py
```

**CÃ¡ch 2: DÃ¹ng Hugging Face CLI**

```bash
# Install CLI
pip install huggingface-hub[cli]

# Login
huggingface-cli login

# Upload
huggingface-cli upload your-username/qwen3-0.6B-instruct-trafficlaws \
    ./qwen3-0.6B-instruct-trafficlaws/model \
    --repo-type model
```

**CÃ¡ch 3: DÃ¹ng Git (Khuyáº¿n nghá»‹ cho files lá»›n)**

```bash
# Clone empty repo
git clone https://huggingface.co/your-username/qwen3-0.6B-instruct-trafficlaws
cd qwen3-0.6B-instruct-trafficlaws

# Copy model files
cp -r ../qwen3-0.6B-instruct-trafficlaws/model/* .

# Commit vÃ  push
git add .
git commit -m "Upload model"
git push
```

### BÆ°á»›c 4: Kiá»ƒm Tra

VÃ o https://huggingface.co/your-username/qwen3-0.6B-instruct-trafficlaws

Äáº£m báº£o táº¥t cáº£ files Ä‘Ã£ Ä‘Æ°á»£c upload:
- âœ… config.json
- âœ… tokenizer files
- âœ… model weights (.safetensors hoáº·c .bin)

## ğŸ”§ Cáº¥u HÃ¬nh Code

### Environment Variable

Set trong Render hoáº·c local:

```env
MODEL_HF_REPO=your-username/qwen3-0.6B-instruct-trafficlaws
```

**LÆ°u Ã½:** Náº¿u set `MODEL_HF_REPO`, code sáº½ tá»± Ä‘á»™ng load tá»« Hugging Face Hub.
Náº¿u khÃ´ng set, sáº½ fallback vá» `MODEL_PATH` (local path).

### Render Environment Variables

Trong Render Dashboard â†’ Environment:
```
MODEL_HF_REPO=your-username/qwen3-0.6B-instruct-trafficlaws
```

**KhÃ´ng cáº§n** set `MODEL_PATH` ná»¯a náº¿u dÃ¹ng Hugging Face Hub.

## ğŸ§ª Test Local

```python
# Test load tá»« Hugging Face
import os
os.environ["MODEL_HF_REPO"] = "your-username/qwen3-0.6B-instruct-trafficlaws"

from backend.inference import load_model
load_model()
```

## ğŸ“ README Template cho Hugging Face Repo

Táº¡o file `README.md` trong repo Hugging Face:

```markdown
---
license: mit
tags:
- legal
- vietnamese
- traffic-laws
- qwen3
- fine-tuned
base_model: Qwen/Qwen3-0.6B-Instruct
---

# Qwen3-0.6B-Instruct-TrafficLaws

Model Ä‘Æ°á»£c fine-tune Ä‘á»ƒ tÆ° váº¥n phÃ¡p luáº­t giao thÃ´ng Viá»‡t Nam.

## Usage

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained(
    "your-username/qwen3-0.6B-instruct-trafficlaws",
    trust_remote_code=True
)
tokenizer = AutoTokenizer.from_pretrained(
    "your-username/qwen3-0.6B-instruct-trafficlaws",
    trust_remote_code=True
)
```
```

## ğŸ” Private Repository

Náº¿u dÃ¹ng private repo, cáº§n set token:

```env
HF_TOKEN=your_huggingface_token
```

Code sáº½ tá»± Ä‘á»™ng sá»­ dá»¥ng token náº¿u cÃ³.

## âš¡ Láº§n Äáº§u Load

- Láº§n Ä‘áº§u load sáº½ download model (cÃ³ thá»ƒ máº¥t vÃ i phÃºt)
- Model sáº½ Ä‘Æ°á»£c cache trong `~/.cache/huggingface/`
- CÃ¡c láº§n sau sáº½ load tá»« cache (nhanh hÆ¡n)

## ğŸ¯ So SÃ¡nh

| Method | Pros | Cons |
|--------|------|------|
| **Hugging Face Hub** | âœ… Dá»… dÃ ng<br>âœ… Tá»± Ä‘á»™ng cache<br>âœ… Version control | âš ï¸ Láº§n Ä‘áº§u download cháº­m |
| **Git LFS** | âœ… Version control | âŒ Cáº§n setup<br>âŒ Files lá»›n |
| **External Storage** | âœ… KhÃ´ng giá»›i háº¡n | âŒ Cáº§n setup<br>âŒ Chi phÃ­ |

## âœ… Checklist

- [ ] Táº¡o tÃ i khoáº£n Hugging Face
- [ ] Login qua CLI: `huggingface-cli login`
- [ ] Táº¡o repository trÃªn Hugging Face
- [ ] Upload model files
- [ ] Kiá»ƒm tra files Ä‘Ã£ upload Ä‘áº§y Ä‘á»§
- [ ] Set `MODEL_HF_REPO` environment variable
- [ ] Test load model tá»« Hugging Face
- [ ] Deploy vÃ  test trÃªn production

## ğŸš€ Sau Khi Upload

1. **Update code**: Code Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t Ä‘á»ƒ há»— trá»£ Hugging Face Hub
2. **Set environment variable**: `MODEL_HF_REPO=your-username/repo-name`
3. **Deploy**: Model sáº½ tá»± Ä‘á»™ng download khi deploy
4. **Done!**: KhÃ´ng cáº§n lo vá» model files ná»¯a!

---

**LÆ°u Ã½:** Model sáº½ Ä‘Æ°á»£c download tá»± Ä‘á»™ng khi app start láº§n Ä‘áº§u. Äáº£m báº£o server cÃ³ Ä‘á»§ disk space (~2-4GB).

